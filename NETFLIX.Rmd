---
title: "Competizone Miss Congeniality"
author: "#saygini"
date: "12/11/2019"
output: html_document
---


TEAM NAME: #saygini

TEAM MEMBERS: Alessandro Cavicchi, Marco Musto, Massimiliano Rubino


## Miss Congeniality

Per questo progetto è stato analizzato il dataset Netflix contenente le recensioni, e le date in cui sono state effettuate, di 100 film di circa 13000 persone. La recensione è espressa in voti da 1 a 5 e l'obiettivo era prevedere quella del film 'Miss Congeniality' sulla base degli altri 99 fim. Di 10000 individui la variabile risposta era osservata e abbiamo stimato una previsione di quella dei restanti.

Data la natura del dataset di grande dimensione, e le variabili da noi create nel feature engeneering, abbiamo scelto di utilizzare una lasso regression poichè trovando il lambda ottimale ci garantisce una stima dei parametri migliore rispetto a quella data da un semplice modello lineare. 


*Summary of the modelling process:*

1. *Preprocessing* <br>
* imputazione dei missing

2. *Missing values* <br>

* Utilizzo dei missing per individuare i film più simili e dissimili al nostro target

* Creazione di 85 dummy che presentavoano 1 qualore il ratings del film era mancante

* imputazione dei missing presente nei ratings con un linear model che utilizzava come regressori tutti i ratings e le dummy create precedentemente



3. *Feature engineering* <br>
* per ogni utente:(votomin,votomax,quantile1,quantile3,media,varianza,)

* media dei film recensiti lo stesso giorno della y

* media 10 film più simili alla y individuati attraverso i missing

* media dei 10 film dissimili alla y individuati attraverso i missing

* effetto tempo sulla valutazione(correlazione tra le valutazioni centrate e le date per ogni individuo)

* media delle differenze tra valutazione dell'utente e valutazione media del film

* media dei rating giorno prima e giorno dopo la valutazione della notra y, con dummy caso in cui l' utente non ha visto alcun film giorno prima o giorno dopo

* per ogni utente effetto individuale del rating giorno prima  e del giorno dopo calcolato attraverso lm 

* aggiunta dei 3 film più simili (individuati con vlutazione NA) come factor: Two Weeks Notice,Sister Act,The Wedding Planner

* aggiunta dei 3 film più dissimili (individuati con vlutazione NA) come factor: Pulp Fiction, Gladiator,American_Beauty

* 85 variabili dummy che andavano ad identificare la posizione del ratings mancante per ogni film

* distanza in numero di giorni tra il primo ratting e ratings di Miss Congenialiti

* aggiunta numero di 1,2 e 5 che ogni utente ha assegnato lo stesso giorno della per Miss Congenialiti

* 99 ratings reifetiti allo stesso giorno che l' utente ha votato Miss congenialiti(stesso dataset iniziale con solo i ratings per ogni film effetuati lo stesso giorno della valutazione data a Miss congenialiti)

* 3 cluster con il metodo dei k means, basati sui ratings, idici distribuzione degli utenti ,e sul dataset totale

* 2 colonna con le previsioni di un modelllo random forest un sampling e down sampling 

* 5  variabili che dovrebbero aggiungere lo score dei dati

* interazioni varie etc...


 
4. *Feature selection* <br>
* intrinseca nel modello 

5. *Final model* <br>
* Modello finale  lasso regrassion con lambda ottimale ($B=0.0018$)

6. *Model tuning and evaluation* <br>
* cross-validation ripetta k=20 e ripetuta 2 volte. Valutazione del tuning parameter attraverso RMSE

7. *R packages* <br>
`library(ggplot2)`
`library(naniar)`
`library(VIM)`
`library(plyr)`
`library(dplyr)`
`library(glmnet)`
`library(rpart)`
`library(rpart.plot)`
`library(caret)`
`library(randomForest)`

8. *References* <br>

```{r startup, include = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = T, eval=T, message=F, warning=F, error=F, comment=NA, cache=F, R.options=list(width=220))
```

**R code to reproduce the last submission**

```{r}
rm(list = ls())
library(ggplot2)
library(naniar)
library(VIM)
library(plyr)
library(dplyr)
library(glmnet)
library(rpart)
library(rpart.plot)
library(caret)
library(randomForest)
setwd("C:/Users/Massimiliano/Desktop/competizione NETFLIX/1_datasets")
test<-"test_ratings_all.dat" 
train<-"train_ratings_all.dat" 
y_train<-"train_y_rating.dat"
y_date_ratings<-"train_y_date.dat"
y_date_ratings_test<-"test_y_date.dat"
train_date_ratings<-"train_dates_all.dat"
test_dates_ratings<-"test_dates_all.dat"
movies<-"movies_name.txt"
test_ratings_all <-read.delim(test, header=FALSE, na.strings="0")
train_ratings_all<-read.delim(train, header=FALSE, na.strings="0")
train_dates_all <- read.delim(train_date_ratings, header=FALSE, na.strings="0")
test_dates_all<-read.delim(test_dates_ratings, header=FALSE, na.strings="0")
y_train_rating<-read.delim(y_train, header=FALSE, na.strings="0")
y_train_date <- read.table(y_date_ratings, quote="\"", comment.char="", na.strings="0")
y_test_date= read.table(y_date_ratings_test, quote="\"", comment.char="", na.strings="0")
movies_name <- read.csv(movies, header=FALSE)
colnames(movies_name)<-c('anno','nome')
colnames(test_ratings_all)<-paste(colnames(test_ratings_all),movies_name$anno,sep = "_")
colnames(train_ratings_all)<-paste(colnames(train_ratings_all),movies_name$anno,sep = "_")
K=5
combiratings<-rbind(train_ratings_all,test_ratings_all)
combidate=rbind(train_dates_all,test_dates_all)
Y=y_train_rating$V1
dateY=c(y_train_date$V1,y_test_date$V1)
y=Y[1:10000]
fun34=function(colonna){
  a=which(is.na(mydata[,colonna]))
  mydata[a,colonna]<<- 0
}
fun34_bis=function(colonna){
  a=which(is.na(mydata1[,colonna]))
  mydata1[a,colonna]<<- 0
}
mydata=as.data.frame(combiratings)
bottiglia=sapply(1:ncol(mydata),fun34)
mydata1=as.data.frame(combiratings)
bottiglia=sapply(1:ncol(mydata1),fun34_bis)
fun35=function(colonna){
  a=which(is.na(mydata2[,colonna]))
  mydata2[a,colonna]<<- 1
  mydata2[-a,colonna]<<-0
  mydata2[,colonna]<<-as.factor(mydata2[,colonna])
}
mydata2=as.data.frame(combiratings)
bottiglia=sapply(15:ncol(mydata2),fun35)
colnames(mydata2)=paste(colnames(mydata2),'d',sep = '')
minimo=function(x) min(x, na.rm = T)
massimo=function(x) max(x, na.rm = T)
media=function(x) mean(x, na.rm = T)
varianza= function(x) var(x, na.rm = T)
quantile1= function(x) summary(x)[2]
quantile3= function(x) summary(x)[5]
MINIMO=apply(combiratings, 1, minimo)
MASSIMO=apply(combiratings, 1, massimo)
MEDIA=apply(combiratings, 1, media)
VARIANZA=apply(combiratings, 1, varianza)
QUANTILE1=apply(combiratings, 1, quantile1)
QUANTILE3=apply(combiratings, 1, quantile3)
MINIMO_T=MINIMO
MASSIMO_T=MASSIMO
MEDIA_T=MEDIA
VARIANZA_T=VARIANZA
QUANTILE1_T=QUANTILE1
QUANTILE3_T=QUANTILE3
DATASET0=(cbind(MINIMO_T,MASSIMO_T,MEDIA_T,VARIANZA_T,QUANTILE1_T,QUANTILE3_T))
FUN1= function(riga){return(length(which(combidate[riga,]-dateY[riga]==0)))}
num_film_stesso_giorno=sapply(1:nrow(combidate),FUN1)
DATASET1=cbind(DATASET0,num_film_stesso_giorno)
FUN2= function(riga){
  a<<-which(combidate[riga,]-dateY[riga]==0)
  ifelse(length(a)>0, mean.default(as.numeric(combiratings[riga,a]),na.rm = T),0)
}
media_film_stesso_giorno=sapply(1:nrow(combiratings),FUN2)
DATASET2=cbind(DATASET1,media_film_stesso_giorno)
fun19=function(colonna) {
  a<<-which(is.na(combiratings[1:10000,colonna]))
  mean.default(y[a])
}
medie_condizionate=sapply(15:99, fun19)
medie_condizionate=as.data.frame(cbind(15:(length(medie_condizionate)+14),medie_condizionate))
medie_condizionate=medie_condizionate[order(medie_condizionate$medie_condizionate),]
medie_condizionate1=medie_condizionate[order(medie_condizionate$medie_condizionate,decreasing = T),]
vettore=medie_condizionate$V1[1:10]
vettore1=medie_condizionate1$V1[1:10]
medie=function(x) mean(x,na.rm = T)
medie_gruppo1=apply(combiratings[,vettore], 1, medie)                                 
medie_gruppo2=apply(combiratings[,vettore1], 1, medie) 
medie_gruppo1[which(is.na(medie_gruppo1))]=mean(medie_gruppo1,na.rm=T)
medie_gruppo2[which(is.na(medie_gruppo2))]=mean(medie_gruppo2,na.rm=T)
DATASET3=cbind(DATASET2,medie_gruppo1,medie_gruppo2)
DATASET4=DATASET3
train_ratings_all_DIFF=apply(combiratings, 2, function(x) x- mean.default(x, na.rm = T) )
FUN4=function(riga) {
  A=cbind(t(combidate[riga,]),(train_ratings_all_DIFF[riga,]))
  a=(which(is.na(A[,1])))
  if(length(a)>0) A<<-A[-a,]
  colnames(A)=c('date','valutazione')
  cor(A[,1],A[,2]) 
}
beta=sapply(1:nrow(combiratings), FUN4 )
beta=round(beta,4);beta[which(is.na(beta))]=0
effetto_tempo=beta*dateY
DATASET5=cbind(DATASET4,effetto_tempo)
delta_votazione_medio=apply((train_ratings_all_DIFF),1,media)
DATASET6=cbind(DATASET5,delta_votazione_medio)
temp=sapply(1:nrow(combiratings),function(riga) (combidate[riga,]-dateY[riga]))
FUN6=function(riga) {
  temp1=unlist(temp[riga,]);a=which(temp1>0);b=min(temp1[a]);
  c=which(temp1==b)
  mean.default(as.numeric(combiratings[riga,c]))
}
temp=t(temp)
temp2=unlist(lapply(1:nrow(combiratings),FUN6))
dummy_last_votation=rep(0,nrow(combiratings) )
dummy_last_votation[which(is.na(temp2))]=1
temp2[which(is.na(temp2))]=mean.default(temp2,na.rm = T)
ratings_after=temp2
DATASET7=cbind(DATASET6,ratings_after,dummy_last_votation)
FUN7=function(riga) {
  temp1=unlist(temp[riga,]);a=which(temp1<0);b=max(temp1[a]);
  c=which(temp1==b)
  mean.default(as.numeric(combiratings[riga,c]))
}
temp3=unlist(lapply(1:nrow(combiratings),FUN7))
temp3[which(is.na(temp3))]=0
ratings_before=temp3
DATASET8=cbind(DATASET7,ratings_before)
FUN8=function(colonna) {
  a=combidate[riga,]-combidate[riga,colonna]
  b=which(a<0);
  if(length(b)==0) (return(0))
  c=max(a[b])
  d=which(a==c)
  e=mean.default(as.numeric(combiratings[riga,d]))
  e
}
FUN9=function(riga){
  riga<<-riga
  A=as.data.frame(cbind(sapply(1:14,FUN8),t(combiratings[riga,1:14])))
  colnames(A)=c('media_pre','Y')
  fit=lm(Y~., data = A)
  round(fit$coefficients[2],4)  
}
beta_pre=sapply(1:nrow(combiratings), FUN9)
dummy_before_votation=rep(0,nrow(combiratings))
beta_pre[which(is.na(beta_pre))]=mean.default(beta_pre,na.rm = T)
posizioni= which(apply(combidate[,1:14], 1, sum)-combidate[,1]*14==0)
dummy_before_votation[posizioni]=1
beta_ratings=beta_pre*ratings_before
DATASET9=cbind(DATASET8,beta_ratings,dummy_before_votation)
medie_col=apply(combiratings, 2, medie)
medie_col=medie_col[1:14]
FUN10=function(riga){
  A=cbind(t(combiratings[riga,1:14]),medie_col )
  colnames(A)=c('Y','medie:col')
  fit=lm(Y~. ,data = as.data.frame(A))
  fit$coefficients[2]}
beta_media=sapply(1:nrow(combiratings), FUN10)
DATASET10=cbind(DATASET9,beta_media)
DATASET12=DATASET10
fun19=function(colonna) {
  a<<-which(is.na(combiratings[1:10000,colonna]))
  mean(y_train_rating$V1[a])
}
medie_condizionate=sapply(15:99, fun19)
medie_condizionate=as.data.frame(cbind(15:(length(medie_condizionate)+14),medie_condizionate))
medie_condizionate=medie_condizionate[order(medie_condizionate$medie_condizionate),]
movies_name$nome[medie_condizionate$V1[1:10]]
medie_condizionate1=medie_condizionate[order(medie_condizionate$medie_condizionate,decreasing = T),]
movies_name$nome[medie_condizionate1$V1[1:10]]
film_simili=as.data.frame(cbind(as.factor(mydata[1:nrow(combiratings),35]),
                                as.factor(mydata[1:nrow(combiratings),33]),
                                as.factor(mydata[1:nrow(combiratings),49])))
film_simili[,1]=as.factor(film_simili[,1])   
film_simili[,2]=as.factor(film_simili[,2])
film_simili[,3]=as.factor(film_simili[,3]) 
colnames(film_simili)=c('Two_Weeks_Notice','Sister_Act','The_Wedding_Planner')  
DATASET13=cbind(DATASET12,film_simili)
DATASET14=cbind(DATASET13,as.factor(mydata[,20]),as.factor(mydata[,26]),as.factor(mydata[,31]))
colnames(DATASET14)=c(colnames(DATASET13),'Pulp_Fiction','Gladiator','American_Beauty')
DATASET15=cbind(DATASET14,mydata)
DATASET18=cbind(DATASET15,mydata2[1:nrow(combiratings),15:99])
FUN15=function(riga) {
  a=combidate[riga,]
  a[which.min(a)]-dateY[riga]
}
distanza_votazione=unlist(sapply(1:nrow(combidate), FUN15))
DATASET19=cbind(DATASET18,distanza_votazione)
FUN18=function(riga){
  a=which(combidate[riga,]-dateY[riga]==0)
  length(which(combiratings[riga,a]==1))
}
FUN19=function(riga){
  a=which(combidate[riga,]-dateY[riga]==0)
  length(which(combiratings[riga,a]==5))
}
FUN20=function(riga){
  a=which(combidate[riga,]-dateY[riga]==0)
  length(which(combiratings[riga,a]==2))
}
numero_di_uno=sapply(1:nrow(combiratings) , FUN18)
numero_di_cinque=sapply(1:nrow(combiratings), FUN19)
numero_di_due=sapply(1:nrow(combiratings), FUN20)
DATASET20=cbind(DATASET19,numero_di_uno,numero_di_cinque,numero_di_due)
DATASET20=DATASET20[,-1]
FUN21=function(colonna) {
  d=which(combidate[riga,]==combidate[riga,colonna])
  if(length(d)==1) (return(0))
  d=d[-which(d==colonna)]
  e=mean.default(as.numeric(combiratings[riga,d]),na.rm = T)
  e
}
FUN22=function(riga){
  riga<<-riga
  A=as.data.frame(cbind(sapply(1:14,FUN21),t(combiratings[riga,1:14])))
  colnames(A)=c('media_now','Y')
  fit=lm(Y~., data = A)
  round(fit$coefficients[2],4)  
}
beta_contemporaneo=sapply(1:nrow(combiratings), FUN22)
effetto_film_stesso_GG=DATASET20$media_film_stesso_giorno*beta_contemporaneo
effetto_film_stesso_GG[which(is.na(effetto_film_stesso_GG))]=mean.default(effetto_film_stesso_GG,na.rm = T)
DATASET21=cbind(DATASET20,abs(effetto_film_stesso_GG))
mydata_no_missing=(mydata)
FUN23=function(colonna){
  A=mydata[,-(colonna)];B=mydata2[,-(colonna)]
  y=mydata[,colonna];b=which(y==0)
  dataset_temp=cbind(A,B)
  ridge.cvtemp<-cv.glmnet(data.matrix(dataset_temp[-b,]),y[-b],alpha=0, nfolds = K, grouped=FALSE)
  hatlambda <-ridge.cvtemp$lambda.min
  yhat.ridge_temp = predict(ridge.cvtemp, s=hatlambda, newx=data.matrix(dataset_temp[-b,]), exact=TRUE)
  yhat.ridge_temp[which(yhat.ridge_temp>5)]=5
  RMSE.ridge_temp= sqrt(mean( (yhat.ridge_temp - y[-b])^2 ))
  print(RMSE.ridge_temp) 
  pred=predict(ridge.cvtemp, s=hatlambda, newx=data.matrix(dataset_temp[b,]), exact=TRUE)
  mydata_no_missing[b,colonna]<<-pred
}
bottiglia=sapply(15:99, FUN23)
DATASET22=cbind(DATASET14,mydata_no_missing,mydata2[1:nrow(combiratings),15:99],distanza_votazione,
                numero_di_uno,numero_di_cinque,numero_di_due,abs(effetto_film_stesso_GG))
FUN16=function(colonna) {
  mydata_riscalato_no_missing[,colonna]<<-mydata_no_missing[,colonna]-DATASET20$MEDIA_T}

mydata_riscalato_no_missing=mydata_no_missing
bottiglia=sapply(1:ncol(mydata_no_missing), FUN16)
DATASET23=cbind(DATASET14,mydata_riscalato_no_missing,mydata2[1:nrow(combiratings),15:99],distanza_votazione,
                numero_di_uno,numero_di_cinque,numero_di_due)
date_diff=combidate
FUN24= function(riga) {
  a=(combidate[riga,]-(dateY[riga]))
  a[which(is.na(a))]=mean.default(a,na.rm = T)
  date_diff[riga,]<<-a
}
FUN25=function(colonna) {
  b=as.numeric(date_diff[,colonna])
  a=which(is.na(date_diff[,colonna]))
  b[a]=mean.default(as.numeric(b),na.rm = T)
  date_diff[,colonna]<<-as.numeric(b)
  }
bottiglia=sapply(1:nrow(combidate), FUN24)
date_diff=data.frame(date_diff)
bottiglia=sapply(1:99, FUN25) 
colnames(date_diff)=paste('date_',colnames(date_diff),sep = '')
DATASET24=cbind(DATASET22,date_diff)
voti_giorno_stesso=combiratings
FUN26= function(riga){
  pos=which(combidate[riga,]-dateY[riga]==0)
  a=rep(0,99)
  a[pos]=combiratings[riga,pos]
  voti_giorno_stesso[riga,]<<-a
  
}
bottiglia=sapply(1:nrow(combidate),FUN26)
colnames(voti_giorno_stesso)=paste('same_day',colnames(voti_giorno_stesso),sep = '')
DATASET25=cbind(DATASET24,voti_giorno_stesso)
FUN27= function(riga){
  a=rep(0,99)
  pos=which((combidate[riga,])==(dateY[riga]))
  if (length(pos>=1)) (a[pos]=1)
  as.factor(a)
  
}
voti_giorno_stesso_DUMMY=t(sapply(1:nrow(combidate),FUN27))
voti_giorno_stesso_DUMMY=as.data.frame(voti_giorno_stesso_DUMMY)
colnames(voti_giorno_stesso_DUMMY)=paste('same_day_D',colnames(voti_giorno_stesso_DUMMY),sep = '')
DATASET26=cbind(DATASET24,voti_giorno_stesso_DUMMY)
FUN28= function(riga){
  a=rep(0,99)
  pos=which((combidate[riga,])==(dateY[riga]))
  if (length(pos>=1)) (a[pos]=1)
  (a)
  
}
voti_giorno_stesso_DUMMY_num=t(sapply(1:nrow(combidate),FUN28))
voti_giorno_stesso_DUMMY_num=as.data.frame(voti_giorno_stesso_DUMMY_num)
clusterdata <- voti_giorno_stesso_DUMMY_num
c_data <- scale(clusterdata)
set.seed(123)
fit <- kmeans(c_data, 2)
mydata <- data.frame( fit$cluster[1:10000],y)
colnames(mydata)=c('cluster','y')
aggregate(mydata,by=list(mydata$cluster),FUN=mean)
table(mydata$cluster) 
clu1 <- which(fit$cluster == 1)
clu2 <- which(fit$cluster != 1)
cluster_film_visti_stesso_giorno=rep(0,nrow(combiratings))
cluster_film_visti_stesso_giorno[clu1]=1
clusterdata <- DATASET26[,214:312]
c_data <- scale(clusterdata) 
fit <- kmeans(c_data, 2)
mydata <- data.frame( fit$cluster[1:10000],y)
colnames(mydata)=c('cluster','y')
aggregate(mydata,by=list(mydata$cluster),FUN=mean)
table(mydata$cluster) 
clu1 <- which(fit$cluster == 1)
clu2 <- which(fit$cluster != 1)
cluster_date_visione_film=rep(0,nrow(combiratings))
cluster_date_visione_film[clu1]=1
for (i in 124:208) {DATASET26[,i]<-as.numeric(DATASET26[,i])-1}
clusterdata <- DATASET26[,124:208]
c_data <- scale(clusterdata) 
fit <- kmeans(c_data, 2) 
mydata <- data.frame( fit$cluster[1:10000],y)
colnames(mydata)=c('cluster','y')
aggregate(mydata,by=list(mydata$cluster),FUN=mean)
table(mydata$cluster) 
clu1 <- which(fit$cluster == 1)
clu2 <- which(fit$cluster != 1)
cluster_missing=rep(0,nrow(combiratings))
cluster_missing[clu1]=1
clusterdata <- DATASET26[,25:123]
c_data <- scale(clusterdata) 
fit <- kmeans(c_data, 2) 
mydata <- data.frame( fit$cluster[1:10000],y)
colnames(mydata)=c('cluster','y')
aggregate(mydata,by=list(mydata$cluster),FUN=mean)
table(mydata$cluster) 
cluster_gradimento_film=as.factor(fit$cluster)
fit <- kmeans(c_data, 5) 
mydata <- data.frame( fit$cluster[1:10000],y)
colnames(mydata)=c('cluster','y')
aggregate(mydata,by=list(mydata$cluster),FUN=mean)
cluster_gradimento_film_multi=as.factor(fit$cluster)
clusterdata <- DATASET26[,1:18]
c_data <- scale(clusterdata) 
fit <- kmeans(c_data, 2) 
mydata <- data.frame( fit$cluster[1:10000],y)
colnames(mydata)=c('cluster','y')
aggregate(mydata,by=list(mydata$cluster),FUN=mean)
table(mydata$cluster) 
cluster_indici_distribuzione=as.factor(fit$cluster)
fit <- kmeans(c_data, 5)
mydata <- data.frame( fit$cluster[1:10000],y)
colnames(mydata)=c('cluster','y')
aggregate(mydata,by=list(mydata$cluster),FUN=mean)
table(mydata$cluster) 
cluster_indici_distribuzione_multi=as.factor(fit$cluster)
clusterdata <- DATASET26[,c(1:18,25:123,209:213)]
c_data <- scale(clusterdata) 
fit <- kmeans(c_data, 2) 
mydata <- data.frame( fit$cluster[1:10000],y)
colnames(mydata)=c('cluster','y')
aggregate(mydata,by=list(mydata$cluster),FUN=mean)
table(mydata$cluster) 
cluster_totale=fit$cluster
fit <- kmeans(c_data, 5) 
mydata <- data.frame( fit$cluster[1:10000],y)
colnames(mydata)=c('cluster','y')
aggregate(mydata,by=list(mydata$cluster),FUN=mean)
table(mydata$cluster) 
cluster_totale_num=fit$cluster
DATASET28_B=cbind(DATASET25,cluster_gradimento_film_multi,cluster_indici_distribuzione_multi,cluster_totale_num)
MY_DATASET1=(DATASET28_B)
MY_DATASET_Y1=as.data.frame(cbind(y,MY_DATASET1[1:10000,]))
ctrl <- trainControl(
  method = "cv",
  number = 10,
  classProbs = TRUE,
  summaryFunction = multiClassSummary
)
mtryGrid = data.frame(mtry=c(2,29,57))
rf <- train(
  make.names(y)~., MY_DATASET_Y1,
  ntree = 50,
  method = "rf",
  tuneGrid = mtryGrid,
  localImp = TRUE,
  trControl=ctrl)
previsioni_RF=predict(rf,MY_DATASET1)
mtryGrid = data.frame(mtry=c(2,29,57))
rf_cinquemila <- train(
  make.names(y[1:5000])~., MY_DATASET_Y1[1:5000,],
  ntree = 50,
  method = "rf",
  tuneGrid = mtryGrid,
  localImp = TRUE,
  trControl=ctrl)

previsioni_RF_cinquemila=predict(rf_cinquemila,MY_DATASET1[5001:10000,])
a=rep(0,length(y))
a[which(y==1)]='a'
a[which(y==2)]='b'
a[which(y==3)]='c'
a[which(y==4)]='d'
a[which(y==5)]='e'
a=as.factor(a)
a=make.names(a)
prova=as.data.frame(cbind(a,MY_DATASET1[1:10000,]))
prova1=prova[5001:10000,]
prova2=prova[1:5000,]
mtryGrid = data.frame(mtry=c(2,29,57))
rf_zero <- train(a~.,prova1, 
  ntree = 50,
  method = "rf",
  tuneGrid = mtryGrid,
  localImp = TRUE,
  trControl=ctrl)
previsioni_RF_zero=as.character(predict(rf_zero,prova2[,-1]))
b=(previsioni_RF_zero)
previsioni_RF_zero[which(b=='a')]='X1'
previsioni_RF_zero[which(b=='b')]='X2'
previsioni_RF_zero[which(b=='c')]='X3'
previsioni_RF_zero[which(b=='d')]='X4'
previsioni_RF_zero[which(b=='e')]='X5'
previsioni_RF_zero=as.factor(previsioni_RF_zero)
previsioni_RF_fin=c(previsioni_RF_zero,previsioni_RF_cinquemila,previsioni_RF[10001:nrow(combiratings)])
previsioni_RF_last=predict(rf_cinquemila,MY_DATASET1[10001:nrow(combiratings),])
previsioni_RF_fin1=c(previsioni_RF_zero,previsioni_RF_cinquemila,previsioni_RF_last)
table(previsioni_RF_fin)
ctrl1 <- trainControl(
  method = "cv",
  number = 10,
  classProbs = TRUE,
  summaryFunction = multiClassSummary
)
ctrl1$sampling='up'
mtryGrid = data.frame(mtry=c(2,29,57))
rf1 <- train(
  make.names(y)~., MY_DATASET_Y1,
  ntree = 50,
  method = "rf",
  tuneGrid = mtryGrid,
  localImp = TRUE,
  trControl=ctrl)
previsioni_RF_down=predict(rf1,MY_DATASET1)
mtryGrid = data.frame(mtry=c(2,29,57))
rf1_cinquemila <- train(
  make.names(y[1:5000])~., MY_DATASET_Y1[1:5000,],
  ntree = 50,
  method = "rf",
  tuneGrid = mtryGrid,
  localImp = TRUE,
  trControl=ctrl1)
previsioni_RF_down_cinquemila=predict(rf1_cinquemila,MY_DATASET1[5001:10000,])
prova1=prova[5001:10000,]
prova2=prova[1:5000,]
rf1_zero <- train(a~.,prova1,
  ntree = 50,
  method = "rf",
  tuneGrid = mtryGrid,
  trControl=ctrl1)
previsioni_RF_down_zero=as.character(predict(rf1_zero,prova2[,-1]))
b=(previsioni_RF_down_zero)
previsioni_RF_down_zero[which(b=='a')]='X1'
previsioni_RF_down_zero[which(b=='b')]='X2'
previsioni_RF_down_zero[which(b=='c')]='X3'
previsioni_RF_down_zero[which(b=='d')]='X4'
previsioni_RF_down_zero[which(b=='e')]='X5'
previsioni_RF_down_zero=as.factor(previsioni_RF_down_zero)
previsioni_RF_fin_down=c(previsioni_RF_down_zero,previsioni_RF_down_cinquemila,previsioni_RF_down[10001:nrow(combiratings)])
previsioni_RF_last_down=predict(rf1_cinquemila,MY_DATASET1[10001:nrow(combiratings),])
previsioni_RF_fin1_down=c(previsioni_RF_down_zero,previsioni_RF_down_cinquemila,previsioni_RF_last_down)
previsioni_RF_fin=as.factor(previsioni_RF_fin)
previsioni_RF_fin_down=as.factor(previsioni_RF_fin_down)
DATASET29=cbind(DATASET28_B,previsioni_RF_fin,previsioni_RF_fin_down)
previsioni_RF_fin1_down=as.factor(previsioni_RF_fin1_down)
previsioni_RF_fin1=as.factor(previsioni_RF_fin1)
DATASET30=cbind(DATASET28_B,previsioni_RF_fin1,previsioni_RF_fin1_down)
for(i in 1:dim(DATASET30)[2]){DATASET30[,i]<-as.numeric(DATASET30[,i])}
for (i in c(19,413,412,414)) {
  DATASET30[,i]=as.factor(DATASET30[,i])
}
control=trainControl(method = "repeatedcv",number=50,repeats = 3)
DATASET30_N=DATASET30
for (i in 1:ncol(DATASET30_N)) {
DATASET30_N[,i]=as.numeric(DATASET30_N[,i])}
MY_DATASET1=cbind(DATASET30_N)
MY_DATASET_Y1=as.data.frame(cbind(y,MY_DATASET1[1:10000,]))
set.seed(123)
lasso_numeric<- train(y~.,data=MY_DATASET_Y1, method = "glmnet",
                      trControl=control,preProc = c("center","scale"),
                      tuneGrid = expand.grid(alpha = 1,
                                             lambda=c(0.0055)))
a1=varImp(lasso_numeric,scale = F)
d1=as.vector(round(a1$importance[,1],3))
d1=as.data.frame(d1)
d1=cbind(d1,rownames(a1$importance))
colnames(d1)=c('valore','nome_riga')
d1=d1[order(d1$valore,decreasing = T),]
posizioni= as.numeric(row.names(d1)[which(d1$valore>0)])
DATASET34=DATASET30_N[,posizioni]
medie_gruppo1_F=cut(DATASET30$medie_gruppo1,5)
media_film_stesso_giorno_F=cut(DATASET30$media_film_stesso_giorno^2,5)
DATASET34=DATASET30_N[,posizioni]
DATASET34$cluster_totale_num=NULL
cluster_gradimento_film_multi=DATASET30$cluster_gradimento_film_multi
cluster_indici_distribuzione_multi=DATASET30$cluster_indici_distribuzione_multi
cluster_totale_num=DATASET30$cluster_totale_num
DATASET34=cbind(DATASET34,cluster_gradimento_film_multi,cluster_indici_distribuzione_multi,cluster_totale_num)
Two_Weeks_Notice=DATASET30$Two_Weeks_Notice
DATASET34=cbind(DATASET34,media_film_stesso_giorno_F,Two_Weeks_Notice)
to.dummy <- function(v = NULL, prefix = NULL){
  #----[ checking the input ]----#
  {
    # check if user has not provided prefix argument
    if (is.null(prefix)) {
      stop("The input \"prefix\" is missing. This will be added to the begining of each column name to avoid conflicts with other column names.")
    }else if (length(prefix) != 1 | nchar(prefix) == 0 | class(prefix) != "character") {
      stop("The input \"prefix\" should be a character vector with length of 1 and character number more than 0.")
    }
    
    
    # check if user has not provided v argument
    if (is.null(v)) {
      stop("The input \"v\" is missing. It should be a vector with categories that you are willing to create dummy variables from. It can be a factor, character or numeric vector.")
    }
  }
  
  
  #----[ pre-processing ]----#
  {
    ## convert to character vector if the input is factor
    if (class(v) == "factor") {
      # get the levels of v
      v_levels <- levels(v)
      # convert the factor to character vector
      v <- as.character(v)
    }else{
      # find tha NAs and turn them into character to have a separate column for NAs
      v[which(is.na(v))] <- "NA"
      # get the categories
      v_levels <- names(table(v, useNA = "ifany"))
    }
  }
  
  
  #----[ processing ]----#
  {
    # go through categories one by one
    for (i in 1:length(v_levels)) { 
      # create a logical vector which has 1 for places that has the category
      assign(x = paste("v", i, sep = ""), value = as.numeric(v == v_levels[i]))
    }
    
    
    # create a cbind command and run it. It attaches the variables generated in the for loop above.
    df <- eval(parse(text = paste("cbind(",
                                  paste('v', 1:i,
                                        sep = '', collapse = ", "),
                                  ")", collapse = "", sep = "")))
    
    # strip the white space from begining and end of the name and the middle white space with "_"
    factor_levels <- gsub("\\s+", "_", gsub("^\\s+|\\s+$", "", v_levels))
    # if one of the levels are "", we should create a name for it, so we use "BLANK"
    factor_levels[which(factor_levels == "")] <- "BLANK"
    # set the colnames
    colnames(df) <- paste(prefix, factor_levels, sep = ".")
    # return the final data.frame
    return(df)
  }
}
dummy_dataset<-as.data.frame(lapply(1:ncol(mydata1),function(x) to.dummy(mydata1[x],colnames(combiratings)[x])))
control=trainControl(method = "repeatedcv",number=5, repeats = 2)
y_uno=ifelse(y==1,1,0)
media_y_uno=length(which(y==1))/length(y)
dataset_score=dummy_dataset
dummy_coding=function(colonna) {
  a=which(dummy_dataset[1:10000,colonna]==1)
  tab <- table((y_uno[a]))
  uno=round(as.numeric(tab['1']/length(a)),3)
  a1=which(dummy_dataset[1:10000,colonna]==0)
  tab1 <- table((y_uno[a1]))
  due=round(as.numeric(tab1['1']/length(a1)),3)
  dataset_score[,colonna]<<-ifelse(dummy_dataset[,colonna]==1,uno-media_y_uno,due-media_y_uno)
}
bottiglia=sapply(1:ncol(dataset_score), dummy_coding)
numerosita=(apply(dummy_dataset,2,sum))
length(which(numerosita>50))/ncol(dataset_score)
colonne_step1_50=which(numerosita>50)
score_50_uno=apply(dataset_score[,colonne_step1_50], 1, function(x) sum(x,na.rm = T))
y_due=ifelse(y==2,1,0)
media_y_due=length(which(y==2))/length(y)
dataset_score2=dummy_dataset
dummy_coding1=function(colonna) {
  a=which(dummy_dataset[1:10000,colonna]==1)
  tab <- table((y_due[a]))
  uno=round(as.numeric(tab['1']/length(a)),3)
  a1=which(dummy_dataset[1:10000,colonna]==0)
  tab1 <- table((y_due[a1]))
  due=round(as.numeric(tab1['1']/length(a1)),3)
  dataset_score2[,colonna]<<-ifelse(dummy_dataset[,colonna]==1,uno-media_y_due,due-media_y_due)
}
bottiglia=sapply(1:ncol(dataset_score2), dummy_coding1)
score_50_due=apply(dataset_score2[,colonne_step1_50], 1, function(x) sum(x,na.rm = T))
y_cinque=ifelse(y==5,1,0)
media_y_cinque=length(which(y==5))/length(y)
dataset_score5=dummy_dataset
dummy_coding5=function(colonna) {
  a=which(dummy_dataset[1:10000,colonna]==1)
  tab <- table((y_cinque[a]))
  uno=round(as.numeric(tab['1']/length(a)),3)
  a1=which(dummy_dataset[1:10000,colonna]==0)
  tab1 <- table((y_cinque[a1]))
  due=round(as.numeric(tab1['1']/length(a1)),3)
  dataset_score5[,colonna]<<-ifelse(dummy_dataset[,colonna]==1,uno-media_y_cinque,due-media_y_cinque)
}
bottiglia=sapply(1:ncol(dataset_score5), dummy_coding5)
score_50_cinque=apply(dataset_score5[,colonne_step1_50], 1, function(x) sum(x,na.rm = T))
DATASET35=cbind(DATASET34,score_50_uno,score_50_due,score_50_cinque)
y_tre=ifelse(y==3,1,0)
media_y_tre=length(which(y==3))/length(y)
dataset_score3=dummy_dataset
dummy_coding3=function(colonna) {
  a=which(dummy_dataset[1:10000,colonna]==1)
  tab <- table((y_tre[a]))
  uno=round(as.numeric(tab['1']/length(a)),3)
  a1=which(dummy_dataset[1:10000,colonna]==0)
  tab1 <- table((y_tre[a1]))
  due=round(as.numeric(tab1['1']/length(a1)),3)
  dataset_score3[,colonna]<<-ifelse(dummy_dataset[,colonna]==1,uno-media_y_tre,due-media_y_tre)
}
bottiglia=sapply(1:ncol(dataset_score3), dummy_coding3)
score_50_tre=apply(dataset_score3[,colonne_step1_50], 1, function(x) sum(x,na.rm = T))
y_quattro=ifelse(y==4,1,0)
media_y_quattro=length(which(y==4))/length(y)
dataset_score4=dummy_dataset
dummy_coding4=function(colonna) {
  a=which(dummy_dataset[1:10000,colonna]==1)
  tab <- table((y_quattro[a]))
  uno=round(as.numeric(tab['1']/length(a)),3)
  a1=which(dummy_dataset[1:10000,colonna]==0)
  tab1 <- table((y_quattro[a1]))
  due=round(as.numeric(tab1['1']/length(a1)),3)
  dataset_score4[,colonna]<<-ifelse(dummy_dataset[,colonna]==1,uno-media_y_quattro,due-media_y_quattro)
}
bottiglia=sapply(1:ncol(dataset_score4), dummy_coding4)
score_50_quattro=apply(dataset_score4[,colonne_step1_50], 1, function(x) sum(x,na.rm = T))
DATASET37=cbind(DATASET35,score_50_tre,score_50_quattro)
DATASET37$cluster_indici_distribuzione_multi=as.numeric(DATASET37$cluster_indici_distribuzione_multi)
DATASET37$cluster_totale_num=as.numeric(DATASET37$cluster_totale_num)
DATASET37$cluster_gradimento_film_multi=as.numeric(DATASET37$cluster_gradimento_film_multi)
MY_DATASET1=cbind(DATASET37,previsioni_RF_fin1_down)
MY_DATASET_Y1=as.data.frame(cbind(y,MY_DATASET1[1:10000,]))
control=trainControl(method = "repeatedcv",number=20, repeats = 2)
set.seed(123)
lasso_caretX2a2<- train(y~.
                          +numero_di_cinque*cluster_gradimento_film_multi
                        +numero_di_uno*Two_Weeks_Notice
                        +cluster_gradimento_film_multi*previsioni_RF_fin1_down
                        +cluster_gradimento_film_multi*Pulp_Fiction
                        +Two_Weeks_Notice*VARIANZA_T
                        +Sister_Act*VARIANZA_T
                        + I(media_film_stesso_giorno^2)+
                          +I(medie_gruppo1^2)+
                          +Pulp_Fiction*V61_1997d
                        +Two_Weeks_Notice*V1_1996+ratings_before*medie_gruppo1+
                          (Two_Weeks_Notice+cluster_gradimento_film_multi+
                             score_50_uno+score_50_cinque+score_50_due+score_50_tre+score_50_quattro)^2
                        
                        ,data=MY_DATASET_Y1, method = "glmnet",
                        trControl=control,preProc = c("center","scale"),
                        tuneGrid = expand.grid(alpha = 1,
                                               lambda=c(0.0018)))
previsioni_lasso_caret=predict(lasso_caretX2a2,MY_DATASET1[(10001:nrow(MY_DATASET1)),])
summary(previsioni_lasso_caret)
previsioni_lasso_caret[which(previsioni_lasso_caret>5)]=5
previsioni_lasso_caret[which(previsioni_lasso_caret<1)]=1
head(previsioni_lasso_caret)
```
